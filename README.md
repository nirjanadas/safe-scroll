<!-- ===================== -->
<!-- SafeScroll App Banner -->
<!-- ===================== -->

<p align="center">
  <img src="assets/safescroll_overview.png" width="100%" />
</p>

<p align="center">
  <img src="assets/safescroll_moderation.png" width="100%" />
</p>

---

# ğŸ›¡ï¸ SafeScroll â€” AI-Powered Social Media Safety Auditor  
**Making your social feed safer â€” one scroll at a time.**

SafeScroll is an **AI-powered Trust & Safety auditing system** that simulates how modern social media platforms internally detect and respond to harmful content and unsafe user behavior.

It demonstrates how **multi-agent GenAI systems** can be applied to:
- content moderation
- underage safety
- grooming detection
- policy enforcement
- human-readable safety reporting

This project is built for **research, demos, and resume-ready showcasing** of real-world AI safety engineering.

---

## ğŸ§  How SafeScroll Works

SafeScroll uses a **multi-agent GenAI architecture**, where each agent focuses on a specific safety responsibility.

### ğŸ”¹ 1. Underage Risk Agent
- Evaluates declared age vs. content style  
- Flags possible underage misrepresentation  
- Outputs a risk score with reasoning  

### ğŸ”¹ 2. Content Safety Agent
Analyzes posts for:
- Bullying & harassment  
- Self-harm indicators  
- Sexual exploitation cues  
- Substance abuse references  

Produces both **per-post** and **aggregated risk levels**.

### ğŸ”¹ 3. Interaction (DM) Risk Agent
- Detects grooming patterns  
- Identifies secrecy pressure & power imbalance  
- Considers age differences in conversations  

### ğŸ”¹ 4. Policy Violation Agent
- Maps AI findings to company safety policies  
- Determines severity  
- Recommends moderation actions (monitor, warn, restrict, escalate)  

### ğŸ”¹ 5. Safety Report Generator
- Combines all agent outputs  
- Generates a clear, human-readable safety report  
- Summarizes risks, evidence, and final recommendation  

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|------|-----------|
| UI | Streamlit |
| Language | Python |
| AI / LLM | OpenAI GPT (multi-agent setup) |
| Data | Synthetic CSV datasets |
| Architecture | Multi-Agent Safety System |
| Styling | Custom Streamlit theme |
| Charts | Streamlit native charts |
 
---

## ğŸ—‚ Folder structure

```text
 safe-scroll/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ safescroll_overview.png
â”‚   â””â”€â”€ safescroll_moderation.png
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ interactions.csv
â”‚   â”œâ”€â”€ posts.csv
â”‚   â””â”€â”€ users.csv
â”œâ”€â”€ policies/
â”‚   â””â”€â”€ safety_policies.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ agents.py
â”œâ”€â”€ app.py
â”œâ”€â”€ generate_synthetic_data.py
â””â”€â”€ requirements.txt
```

---

## â–¶ï¸ Running the App Locally

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/nirjanadas/safe-scroll.git
cd safe-scroll
```
2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```
3ï¸âƒ£ Run the app
```bash
streamlit run app.py
```
---

## ğŸ“Š Output & Reports

SafeScroll generates:
- Structured JSON risk analysis
- Visual risk indicators
- Policy violation summary
- Final human-readable safety report

---

## ğŸ“Œ Disclaimer

All user data is synthetic and used only for research and demonstration purposes.




